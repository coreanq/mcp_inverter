import os, sys, json
import pandas as pd

import asyncio
import streamlit as st
from openai.types.responses import ResponseTextDeltaEvent
from agents import Agent, Runner, ItemHelpers
from agents.mcp import MCPServerStdio


################################################################################################################################
import logging
from dotenv import load_dotenv
load_dotenv()  # load environment variables from .env
# ANSI ì´ìŠ¤ì¼€ì´í”„ ì½”ë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
COLOR_RED = "\033[91m"
COLOR_RESET = "\033[0m"

class ColoredFormatter(logging.Formatter):
    def format(self, record):
        if (record.levelno >= logging.ERROR):
            record.msg = COLOR_RED + record.msg + COLOR_RESET
        return super().format(record)

# ë¡œê·¸ í¬ë§·ì„ ì •ì˜í•©ë‹ˆë‹¤. ì—ëŸ¬ ë©”ì‹œì§€ì— ìƒ‰ìƒì„ ì ìš©í•©ë‹ˆë‹¤.
formatter = ColoredFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# í•¸ë“¤ëŸ¬ë¥¼ ìƒì„±í•˜ê³  í¬ë§·í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
handler = logging.StreamHandler()
handler.setFormatter(formatter)

logger = logging.getLogger(__name__)
logger.addHandler(handler)
logger.setLevel(logging.INFO) # í•„ìš”ì— ë”°ë¼ ë¡œê·¸ ë ˆë²¨ì„ ì„¤ì •í•©ë‹ˆë‹¤.


# [ {user_input: {}, reponse: ""}, ... ]
user_prompt_cache = []

################################################################################################################################
DATABASE_FILE = os.path.join(os.path.dirname(__file__), 'output.json')

json_data = None

def load_backend_data():
    # ì—‘ì…€ íŒŒì¼ ì½ê¸° (í•œ ë²ˆë§Œ ë¡œë“œ)
    global json_data
    try:
        with open(DATABASE_FILE, "r", encoding="utf-8") as f:
            json_data = json.load(f)
        
        logger.info(f"DATABASE íŒŒì¼ '{DATABASE_FILE}' ë¡œë“œ ì™„ë£Œ.")
    except FileNotFoundError:
        logger.error(f"ì˜¤ë¥˜: '{DATABASE_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        df = None
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜: '{DATABASE_FILE}' íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ - {e}")
        df = None


################################################################################################################################
# Windows í˜¸í™˜ì„±
# if sys.platform == "win32":
#     asyncio.set_event_loop_policy()

# MCP ì„œë²„ ì„¤ì •
async def setup_mcp_servers():
    servers = []
    
    # mcp.json íŒŒì¼ì—ì„œ ì„¤ì • ì½ê¸°
    with open('mcp.json', 'r') as f:
        config = json.load(f)
    
    # êµ¬ì„±ëœ MCP ì„œë²„ë“¤ì„ ìˆœíšŒ
    for server_name, server_config in config.get('mcpServers', {}).items():
        mcp_server = MCPServerStdio(
            params={
                "command": server_config.get("command"),
                "args": server_config.get("args", [])
            },
            cache_tools_list=True
        )
        await mcp_server.connect()
        servers.append(mcp_server)

    return servers


# ì—ì´ì „íŠ¸ ì„¤ì •
async def setup_agent():
    # ì„œë²„ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±
    mcp_servers = await setup_mcp_servers()
    
    agent = Agent(
        name="Assistant",
        instructions="ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ mcp server ë¥¼ ì‚¬ìš©í•´ ìš”ì²­ì‚¬í•­ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ì•¼",
        model="gpt-4o-mini",
        mcp_servers=mcp_servers,
    )
    return agent,mcp_servers


# ë©”ì‹œì§€ ì²˜ë¦¬
async def process_user_message():
    agent,mcp_servers = await setup_agent()
    messages = json.dumps(user_prompt_cache, ensure_ascii=False).encode("utf-8")
    result = Runner.run_streamed(agent, input=messages)

    response_text = ""
    placeholder = st.empty()

    async for event in result.stream_events():
        # LLM ì‘ë‹µ í† í° ìŠ¤íŠ¸ë¦¬ë°
        if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
            response_text += event.data.delta or ""
            with placeholder.container():
                with st.chat_message("assistant"):
                    st.markdown(response_text)


        # ë„êµ¬ ì´ë²¤íŠ¸ì™€ ë©”ì‹œì§€ ì™„ë£Œ ì²˜ë¦¬
        elif event.type == "run_item_stream_event":
            item = event.item

            if item.type == "tool_call_item":
                logger

    # ëª…ì‹œì  ì¢…ë£Œ (streamlitì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ ì˜¤ë¥˜ ë°©ì§€)
    for server in mcp_servers:
        await server.__aexit__(None, None, None)

messages = []

async def main():
    agent,mcp_servers = await setup_agent()
    

    while True:
        user_input = input("\nYou: ")
        messages.append({"role": "user", "content": user_input})

        result = Runner.run_streamed(
            agent, 
            input=messages
        )
        
        response_text = '' 
        async for event in result.stream_events():
            # We'll ignore the raw responses event deltas
            if event.type == "raw_response_event":
                continue
            # When the agent updates, print that
            elif event.type == "agent_updated_stream_event":
                # print(f"Agent updated: {event.new_agent.name}")
                continue
            # When items are generated, print them
            elif event.type == "run_item_stream_event":
                if event.item.type == "tool_call_item":
                    print("-- Tool was called")
                elif event.item.type == "tool_call_output_item":
                    print(f"-- Tool output: {event.item.output}")
                elif event.item.type == "message_output_item":
                    response_text = ItemHelpers.text_message_output(event.item)
                    print(f"-- Message output:\n {response_text}", flush= True)
                    messages.append( { "role": "assistant", "content": response_text })
                else:
                    pass  # Ignore other event types

        print("=== Run complete ===\n\n")
        # async for event in result.stream_events():
        #     print(event)
        #     # LLM ì‘ë‹µ í† í° ìŠ¤íŠ¸ë¦¬ë°
        #     if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
        #         response_text += event.data.delta or ""
        #         print(f"Assistant: {response_text}", end="", flush= True)
        #         messages.append({"role": "assistant", "content": response_text})

        #     # ë„êµ¬ ì´ë²¤íŠ¸ì™€ ë©”ì‹œì§€ ì™„ë£Œ ì²˜ë¦¬
        #     elif event.type == "run_item_stream_event":
        #         item = event.item
        #         if item.type == "tool_call_item":
        #             tool_name = item.raw_item.name
        #             print(f"ğŸ›  ë„êµ¬ í™œìš©: `{tool_name}`", flush= True)

if __name__ == "__main__":
    load_backend_data()
    asyncio.run(main())